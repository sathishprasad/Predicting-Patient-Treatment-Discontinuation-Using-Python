{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Patient Discontinuation Prediction Model"
      ],
      "metadata": {
        "id": "DYphSDQUx_Mz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5lTaStOSjE2"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd    # Data manipulation library\n",
        "import numpy as np     # Numerical operations library\n",
        "import xgboost as xgb  # XGBoost library for gradient boosting\n",
        "import optuna          # Optimization library for hyperparameter tuning\n",
        "import matplotlib.pyplot as plt  # Plotting library\n",
        "\n",
        "from sklearn.model_selection import train_test_split  # For data splitting\n",
        "from sklearn.metrics import roc_auc_score            # Metric for evaluation\n",
        "from sklearn.preprocessing import StandardScaler     # For data scaling\n",
        "from itertools import combinations                   # For feature interactions\n",
        "from xgboost import XGBClassifier                    # XGBoost classifier\n",
        "from sklearn.model_selection import StratifiedKFold  # Cross-validation\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from catboost import CatBoostClassifier, Pool # Additional evaluation metrics\n",
        "\n",
        "# Reading training and testing data from CSV files\n",
        "train_data = pd.read_csv(\"/content/prepared_combined.csv\")  # Read training data from a CSV file\n",
        "test_data = pd.read_csv(\"/content/prepared_test.csv\")      # Read testing data from a CSV file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3l-ciQGTWIx"
      },
      "outputs": [],
      "source": [
        "# Splitting training and testing data into input (features) and output (target) variables\n",
        "# For training data:\n",
        "train_data_x = train_data.iloc[:, 8:]    # Extract features from training data, starting from the 9th column\n",
        "train_data_y = train_data.iloc[:, 4:5]   # Extract target variable from training data, 5th column\n",
        "\n",
        "# For testing data:\n",
        "test_data_x = test_data.iloc[:, 6:]      # Extract features from testing data, starting from the 7th column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkjkWS3kTzlN"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame 'df' for training data and remove specific columns\n",
        "df = train_data_x\n",
        "df = df.drop('sath', axis=1)  # Remove the 'sath' column\n",
        "df = df.drop('id_t', axis=1)  # Remove the 'id_t' column\n",
        "\n",
        "# Get the column names and indices\n",
        "column_names = df.columns\n",
        "column_indices = range(len(column_names))\n",
        "\n",
        "# Calculate pairwise interactions (products) between columns\n",
        "interactions = []\n",
        "\n",
        "for col1_index, col2_index in combinations(column_indices, 2):\n",
        "    col1_name = column_names[col1_index]\n",
        "    col2_name = column_names[col2_index]\n",
        "    product = df.iloc[:, col1_index] * df.iloc[:, col2_index]\n",
        "    interaction_name = f\"{col1_name}_{col2_name}_interaction\"\n",
        "    df[interaction_name] = product\n",
        "    interactions.append(interaction_name)\n",
        "\n",
        "# Create a DataFrame 'df2' for testing data and remove specific columns\n",
        "df2 = test_data_x\n",
        "df2 = df2.drop('sath', axis=1)  # Remove the 'sath' column\n",
        "df2 = df2.drop('id_t', axis=1)  # Remove the 'id_t' column\n",
        "\n",
        "# Get the column names and indices\n",
        "column_names = df2.columns\n",
        "column_indices = range(len(column_names))\n",
        "\n",
        "# Calculate pairwise interactions (products) between columns for testing data\n",
        "interactions = []\n",
        "\n",
        "for col1_index, col2_index in combinations(column_indices, 2):\n",
        "    col1_name = column_names[col1_index]\n",
        "    col2_name = column_names[col2_index]\n",
        "    product = df2.iloc[:, col1_index] * df2.iloc[:, col2_index]\n",
        "    interaction_name = f\"{col1_name}_{col2_name}_interaction\"\n",
        "    df2[interaction_name] = product\n",
        "    interactions.append(interaction_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the 'est_age' column to the training and testing DataFrames\n",
        "df['est_age'] = train_data['est_age']\n",
        "df2['est_age'] = test_data['est_age']\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to your training data and transform it\n",
        "X_train_scaled = scaler.fit_transform(df)\n",
        "\n",
        "# Use the same scaler to transform your test data\n",
        "X_test_scaled = scaler.transform(df2)\n",
        "\n",
        "# Create DataFrames for scaled training and testing data\n",
        "df = pd.DataFrame(X_train_scaled, columns=df.columns)\n",
        "df2 = pd.DataFrame(X_test_scaled, columns=df2.columns)\n"
      ],
      "metadata": {
        "id": "1pII35gb6WFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2Y5h2bkUcdz"
      },
      "outputs": [],
      "source": [
        "# Add the 'race_cd' and 'sex_cd' columns to the training and testing DataFrames\n",
        "df['race_cd'] = train_data['race_cd']\n",
        "df['sex_cd'] = train_data['sex_cd']\n",
        "\n",
        "# One-hot encode the 'sex_cd' column in the training data\n",
        "df = pd.get_dummies(df, columns=['sex_cd'], drop_first=True)\n",
        "\n",
        "# Add the 'race_cd' and 'sex_cd' columns to the testing DataFrames\n",
        "df2['race_cd'] = test_data['race_cd']\n",
        "df2['sex_cd'] = test_data['sex_cd']\n",
        "\n",
        "# One-hot encode the 'sex_cd' column in the testing data\n",
        "df2 = pd.get_dummies(df2, columns=['sex_cd'], drop_first=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1Nt_qd7Zte1"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df,train_data_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a CatBoost dataset for training and testing\n",
        "train_data = Pool(data=X_train, label=y_train)\n",
        "test_data = Pool(data=X_test, label=y_test)\n",
        "\n",
        "# Initialize the CatBoost classifier\n",
        "catboost_model = CatBoostClassifier(**parameters)\n",
        "\n",
        "# Train the model\n",
        "catboost_model.fit(train_data, eval_set=test_data)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = catboost_model.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print(f\"AUC on the test set: {auc}\")\n",
        "\n",
        "# Feature Importance\n",
        "feature_importance = catboost_model.get_feature_importance()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mdei2o10NsJh"
      },
      "outputs": [],
      "source": [
        "feature_importance = catboost_model.get_feature_importance()\n",
        "num_features_to_select = 325  # Change this to your desired number of features\n",
        "top_feature_indices = np.argsort(feature_importance)[::-1][:num_features_to_select]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    model = CatBoostClassifier(\n",
        "         iterations=trial.suggest_int('iterations', 32, 1024),\n",
        "         learning_rate=trial.suggest_float('learning_rate', 0.001, 0.3),\n",
        "         depth=trial.suggest_int('depth', 1, 10),\n",
        "         l2_leaf_reg=trial.suggest_float('l2_leaf_reg', 0.01, 10),\n",
        "         grow_policy=trial.suggest_categorical('grow_policy', ['Depthwise']),\n",
        "         bootstrap_type=trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli']),\n",
        "         od_type=trial.suggest_categorical('od_type', ['Iter']),\n",
        "         eval_metric=trial.suggest_categorical('eval_metric', ['AUC']),  # Use AUC as the evaluation metric\n",
        "         loss_function=trial.suggest_categorical('loss_function', ['Logloss']),\n",
        "         random_state=trial.suggest_categorical('random_state', [42]),\n",
        "         verbose=trial.suggest_categorical('verbose', [0])\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "         X_train, y_train,\n",
        "         eval_set=[(X_train, y_train), (X_val, y_val)],\n",
        "         verbose=False\n",
        "    )\n",
        "\n",
        "     # Use roc_auc_score as the evaluation metric\n",
        "    auc_score = roc_auc_score(y_val, model.predict(X_val))\n",
        "    return auc_score  # AUC score is used for hyperparameter optimization\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.iloc[:, top_feature_indices], train_data_y, test_size=0.2, random_state=42)\n",
        "import optuna\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "best_hyperparams = study.best_params\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UwUQRq-RT6Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hyperparams = {'iterations': 796,\n",
        "                    'learning_rate': 0.20846308782767234,\n",
        "                    'depth': 8,\n",
        "                    'l2_leaf_reg': 0.6003745928817406,\n",
        "                    'grow_policy': 'Depthwise',\n",
        "                    'bootstrap_type': 'Bernoulli',\n",
        "                    'od_type': 'Iter',\n",
        "                    'eval_metric': 'AUC',\n",
        "                    'loss_function': 'Logloss',\n",
        "                    'random_state': 42,\n",
        "                    'verbose': 0}\n",
        "\n",
        "parameters = {'iterations': 681,\n",
        "              'learning_rate': 0.2775361994919723,\n",
        "              'depth': 8, 'l2_leaf_reg': 6.961173375158855,\n",
        "              'grow_policy': 'Depthwise',\n",
        "              'bootstrap_type': 'Bayesian',\n",
        "              'od_type': 'Iter',\n",
        "              'eval_metric': 'AUC',\n",
        "              'loss_function': 'Logloss',\n",
        "              'random_state': 42,\n",
        "              'verbose': 0}"
      ],
      "metadata": {
        "id": "DN-Dg39aXFLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, top_feature_indices], train_data_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the CatBoostClassifier with your hyperparameters\n",
        "model = CatBoostClassifier(**parameters)\n",
        "\n",
        "# Perform 5-fold cross-validation (you can change the number of folds)\n",
        "cv_scores_auc = cross_val_score(model, df.iloc[:, top_feature_indices], train_data_y, cv=5, scoring='f1_micro')\n",
        "#cv_scores_accuracy = cross_val_score(model, df.iloc[:, top_feature_indices], train_data_y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Print the cross-validation scores for AUC and accuracy\n",
        "print(\"Cross-Validation AUC Scores:\", cv_scores_auc)\n",
        "print(\"Mean AUC:\", cv_scores_auc.mean())\n",
        "\n",
        "#print(\"Cross-Validation Accuracy Scores:\", cv_scores_accuracy)\n",
        "#print(\"Mean Accuracy:\", cv_scores_accuracy.mean())\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the training data\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Calculate F1 score for training data (micro average)\n",
        "train_score_micro = f1_score(y_train, y_train_pred, average='micro')\n",
        "print(\"Training F1 Score (Micro Average):\", train_score_micro)\n"
      ],
      "metadata": {
        "id": "we1dA7PpLAOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, top_feature_indices]\n",
        "y = train_data_y\n",
        "\n",
        "# Initialize the CatBoostClassifier with your best hyperparameters\n",
        "model = CatBoostClassifier(**parameters)\n",
        "\n",
        "# Initialize StratifiedKFold with 5 folds and shuffle=True\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Lists to store metrics for each fold\n",
        "f1_scores_micro = []\n",
        "auc_scores = []\n",
        "accuracy_scores = []\n",
        "\n",
        "# Perform cross-validation\n",
        "for train_index, test_index in kf.split(X, y):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate and store the F1 score (micro average) for this fold\n",
        "    f1_micro = f1_score(y_test, y_test_pred, average='micro')\n",
        "    f1_scores_micro.append(f1_micro)\n",
        "\n",
        "    # Calculate and store the AUC score for this fold\n",
        "    y_test_proba = model.predict(X_test) # Probability of class 1\n",
        "    auc = roc_auc_score(y_test, y_test_proba)\n",
        "    auc_scores.append(auc)\n",
        "\n",
        "    # Calculate and store the accuracy for this fold\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    accuracy_scores.append(accuracy)\n",
        "\n",
        "# Print the evaluation metrics for each fold\n",
        "for fold, (f1_micro, auc, accuracy) in enumerate(zip(f1_scores_micro, auc_scores, accuracy_scores), 1):\n",
        "    print(f\"Fold {fold}:\")\n",
        "    print(f\"  F1 Score (Micro Average) = {f1_micro:.4f}\")\n",
        "    print(f\"  AUC = {auc:.4f}\")\n",
        "    print(f\"  Accuracy = {accuracy:.4f}\")\n",
        "    print()\n",
        "\n",
        "# Calculate and print the mean metrics across all folds\n",
        "mean_f1_micro = sum(f1_scores_micro) / len(f1_scores_micro)\n",
        "mean_auc = sum(auc_scores) / len(auc_scores)``\n",
        "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "\n",
        "print(f\"Mean F1 Score (Micro Average) = {mean_f1_micro:.4f}\")\n",
        "print(f\"Mean AUC = {mean_auc:.4f}\")\n",
        "print(f\"Mean Accuracy = {mean_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "lVU4ww59qmjU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlPRd2CLSKG_"
      },
      "outputs": [],
      "source": [
        "# Create a CatBoost classifier\n",
        "model = CatBoostClassifier(**parameters)\n",
        "# Train the model on the training data\n",
        "model.fit(df.iloc[:, top_feature_indices], train_data_y)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_prob = model.predict_proba(df2.iloc[:, top_feature_indices])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7KSi4X4XD8u"
      },
      "outputs": [],
      "source": [
        "final_df = pd.DataFrame()\n",
        "final_df['ID'] = test_data[['id']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1p4lwF_XFS2"
      },
      "outputs": [],
      "source": [
        "final_df['SCORE'] = y_prob[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjIpxVOyX0fi"
      },
      "outputs": [],
      "source": [
        "final_df['RANK'] = final_df['SCORE'].rank(ascending=False).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABCVkBjCYFhX"
      },
      "outputs": [],
      "source": [
        "submission_df = final_df\n",
        "# Scatter plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(submission_df['RANK'], submission_df['SCORE'], s=10)\n",
        "plt.title('Scatter Plot of Rank vs. Score')\n",
        "plt.xlabel('Rank')\n",
        "plt.ylabel('Score')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JM13tkKlYuTD"
      },
      "outputs": [],
      "source": [
        "submission_df.to_csv(\"2023CaseCompetition_Sathish_Prasad_20231005.csv\",index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}